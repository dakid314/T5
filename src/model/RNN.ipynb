{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from sklearn.model_selection import  StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, confusion_matrix, precision_score, accuracy_score, f1_score, matthews_corrcoef, auc,precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def get_evaluation(label: list, pred: list, pro_cutoff: float = None):\n",
    "    fpr, tpr, thresholds = roc_curve(label, pred)\n",
    "    if pro_cutoff is None:\n",
    "        best_one_optimal_idx = np.argmax(tpr - fpr)\n",
    "        pro_cutoff = thresholds[best_one_optimal_idx]\n",
    "    pred_l = [1 if i >= pro_cutoff else 0 for i in pred]\n",
    "    #后面新增的计算prAUC\n",
    "    confusion_matrix_1d = confusion_matrix(label, pred_l).ravel()\n",
    "    confusion_dict = {N: n for N, n in zip(['tn', 'fp', 'fn', 'tp'], list(\n",
    "        confusion_matrix_1d * 2 / np.sum(confusion_matrix_1d)))}\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(label, pred)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    \n",
    "    evaluation = {\n",
    "        \"accuracy\": accuracy_score(label, pred_l),\n",
    "        \"precision\": precision_score(label, pred_l),\n",
    "        \"f1_score\": f1_score(label, pred_l),\n",
    "        \"mmc\": matthews_corrcoef(label, pred_l),\n",
    "        \"rocAUC\": auc(fpr, tpr),\n",
    "        \"prAUC\": pr_auc,\n",
    "        \"specificity\": confusion_dict['tn'] / (confusion_dict['tn'] + confusion_dict['fp']),\n",
    "        \"sensitivity\": confusion_dict['tp'] / (confusion_dict['tp'] + confusion_dict['fn']),\n",
    "        'pro_cutoff': pro_cutoff\n",
    "    }\n",
    "    return evaluation\n",
    "\n",
    "def plot_roc_curve(target, pred, path_to_: str):\n",
    "    fpr, tpr, thresholds = roc_curve(target, pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(19.2, 10.8))\n",
    "    plt.plot(fpr, tpr, color='red', lw=2,\n",
    "             label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='blue', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic (ROC) curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    plt.savefig(f\"{path_to_}\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dropout,Dense\n",
    "from sklearn.metrics import roc_curve, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_test_Data=[]\n",
    "non_train_Data=[]\n",
    "test_Data=[]\n",
    "train_Data=[]\n",
    "predict_Data = []\n",
    "first_greater_than_found = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    input1 = tf.keras.Input(shape=(100,))\n",
    "       \n",
    "    embedding_layer = tf.keras.layers.Embedding(21, 100)(input1)\n",
    "    \n",
    "    dorp1 = tf.keras.layers.Dropout(rate=0.2)(embedding_layer)\n",
    "    lstm1 = tf.keras.layers.LSTM(units=100,input_shape = (100,100),return_sequences=True)(dorp1)\n",
    "    \n",
    "    dorp2 = tf.keras.layers.Dropout(rate=0.2)(lstm1)\n",
    "    lstm2 = tf.keras.layers.LSTM(units=100,input_shape = (100,100),return_sequences=True)(dorp2)\n",
    "    \n",
    "    dorp3 = tf.keras.layers.Dropout(rate=0.2)(lstm2)\n",
    "    lstm3 = tf.keras.layers.LSTM(units=100,input_shape = (100,100),return_sequences=True)(dorp3)\n",
    "    \n",
    "    flatten_layer = tf.keras.layers.Flatten()(lstm3)\n",
    "    output_layer = tf.keras.layers.Dense(1,activation='sigmoid')(flatten_layer)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=input1, outputs=output_layer, name='Rnn')\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                  metrics=[\n",
    "                      tf.keras.metrics.BinaryAccuracy(),\n",
    "                      tf.keras.metrics.AUC(name='auc')\n",
    "                  ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os \n",
    "class MyOptimitzer:\n",
    "    def __init__(self,full_X,full_y) -> None:\n",
    "\n",
    "        self.train_best_predicted_pair = None\n",
    "        self.train_best_5C_predicted_pair = None\n",
    "        self.best_predicted_pair = None\n",
    "        self.best_5C_predicted_pair = None\n",
    "        self.end_of_train_time = None\n",
    "        pass\n",
    "        \n",
    "        for Kfold_id, (train_id, test_id) in enumerate(\n",
    "            StratifiedKFold(\n",
    "                n_splits=5,\n",
    "                shuffle=True,\n",
    "                random_state=42\n",
    "            ).split(full_X, full_y)\n",
    "        ):\n",
    "            y_to_train = full_y[train_id].copy()\n",
    "            fiveC_model = get_model()\n",
    "            fiveC_model.fit(\n",
    "                full_X[train_id],\n",
    "                y_to_train,\n",
    "                epochs=100,\n",
    "                batch_size=15,\n",
    "                callbacks=[\n",
    "                tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='val_auc', min_delta=0, patience=3, verbose=0,\n",
    "                mode='auto', baseline=None, restore_best_weights=True\n",
    "                ),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            # 预测并记录\n",
    "            self.best_5C_predicted_pair.append([\n",
    "                np.nan_to_num(fiveC_model.predict_proba(\n",
    "                    X=full_X[test_id]\n",
    "                ), nan=0.0),\n",
    "                full_y[test_id]\n",
    "            ])\n",
    "            self.train_best_5C_predicted_pair.append([\n",
    "                np.nan_to_num(fiveC_model.predict_proba(\n",
    "                    X=full_X[train_id]\n",
    "                ), nan=0.0),\n",
    "                y_to_train\n",
    "            ])\n",
    "\n",
    "        return self\n",
    "    def get_summary(self, path_to_dir: str = None):\n",
    "        os.makedirs(path_to_dir, exist_ok=True)\n",
    "        model_path = \"-\"\n",
    "        \n",
    "\n",
    "        model_path = f\"{path_to_dir}/{self.classifier_name}.pkl\"\n",
    "        if path_to_dir is not None:\n",
    "            with open(model_path, \"bw+\") as f:\n",
    "                pickle.dump(\n",
    "                    self.grid_search, f\n",
    "                )\n",
    "            \n",
    "        training_testing_performance = get_evaluation(\n",
    "            label=self.best_predicted_pair[1],\n",
    "            pred=self.best_predicted_pair[0][:, 1],\n",
    "        )\n",
    "\n",
    "        # 计算5C中的平均表现\n",
    "        FiveFold_result = {}\n",
    "        for keys in training_testing_performance.keys():\n",
    "            value_list = []\n",
    "            for item in self.best_5C_predicted_pair:\n",
    "\n",
    "                item_performance = get_evaluation(\n",
    "                    label=item[1],\n",
    "                    pred=item[0][:, 1],\n",
    "                )\n",
    "                value_list.append(item_performance[keys])\n",
    "\n",
    "            if keys == \"pro_cutoff\":\n",
    "                FiveFold_result[keys] = value_list\n",
    "            else:\n",
    "                FiveFold_result[keys] = sum(value_list) / len(value_list)\n",
    "\n",
    "\n",
    "        return pd.Series({\n",
    "                        \"Classifier_Name\": self.classifier_name,\n",
    "                        \"Optimitied_Param\": dict(self.grid_search.best_params_),\n",
    "                        \"Model_Path\": model_path\n",
    "                    } | FiveFold_result\n",
    "                        )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    seq = []\n",
    "    with open(path) as pos:\n",
    "        sequence = \"\" \n",
    "        for line in pos:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\">\"):       \n",
    "                if sequence != \"\":\n",
    "                    if len(sequence) >= 100:\n",
    "                        sequence = sequence[:100]\n",
    "                        predict_Data.append(sequence)\n",
    "                    sequence = \"\"\n",
    "            else:\n",
    "                sequence += line\n",
    "            if sequence != \"\":\n",
    "                if len(sequence) >= 100:\n",
    "                    sequence = sequence[:100]\n",
    "                    seq.append(sequence)\n",
    "\n",
    "pos_sequence = pd.Series(load_data())\n",
    "neg_sequence = pd.Series(load_data())\n",
    "pos_label = np.ones((len(pos_sequence)))\n",
    "neg_label = np.zeros((len(neg_sequence)))\n",
    "full_y = pd.concat([pos_label,neg_label])\n",
    "full_X = pd.concat([pos_sequence,neg_sequence])\n",
    "\n",
    "tokenizer = Tokenizer(full_X)\n",
    "tokenizer.fit_on_texts(full_X)\n",
    "full_X = tokenizer.texts_to_sequences(full_X)\n",
    "full_X = np.array(full_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path_to_save = f'/mnt/md0/Public/T5/model/'\n",
    "os.makedirs(model_path_to_save, exist_ok=True)\n",
    "\n",
    "result_list = []\n",
    "fivecross_result = pd.concat([MyOptimitzer().get_summary(path_to_dir=f\"{model_path_to_save}/\")], axis=1)\n",
    "\n",
    "fivecross_result_splited = fivecross_result.loc[:, [\n",
    "    \"accuracy\", \"precision\", \"f1_score\", \"mmc\", \"rocAUC\", \"specificity\", \"sensitivity\", \"pro_cutoff\",\"prAUC\"]]\n",
    "fivecross_result_splited.to_csv(\n",
    "    f\"{model_path_to_save}/5Fold.csv\"\n",
    ")\n",
    "\n",
    "series = fivecross_result_splited.sum(axis=0)\n",
    "result_list.append(series)\n",
    "\n",
    "pd.concat(\n",
    "result_list, axis=1,\n",
    ").T.to_csv(\n",
    "f\"{model_path_to_save}/5fold_results.csv\",\n",
    "index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "MyOptimitzer.__init__() missing 2 required positional arguments: 'full_X' and 'full_y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 222\u001b[0m\n\u001b[1;32m    219\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(model_path_to_save, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    221\u001b[0m result_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 222\u001b[0m fivecross_result \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\u001b[43mMyOptimitzer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget_summary(path_to_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_path_to_save\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    224\u001b[0m fivecross_result_splited \u001b[38;5;241m=\u001b[39m fivecross_result\u001b[38;5;241m.\u001b[39mloc[:, [\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1_score\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmmc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrocAUC\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecificity\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msensitivity\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpro_cutoff\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprAUC\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m    226\u001b[0m fivecross_result_splited\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_path_to_save\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/5Fold.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    228\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: MyOptimitzer.__init__() missing 2 required positional arguments: 'full_X' and 'full_y'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from sklearn.model_selection import  StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, confusion_matrix, precision_score, accuracy_score, f1_score, matthews_corrcoef, auc,precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dropout,Dense\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import pickle\n",
    "import os \n",
    "\n",
    "def get_evaluation(label: list, pred: list, pro_cutoff: float = None):\n",
    "    fpr, tpr, thresholds = roc_curve(label, pred)\n",
    "    if pro_cutoff is None:\n",
    "        best_one_optimal_idx = np.argmax(tpr - fpr)\n",
    "        pro_cutoff = thresholds[best_one_optimal_idx]\n",
    "    pred_l = [1 if i >= pro_cutoff else 0 for i in pred]\n",
    "    #后面新增的计算prAUC\n",
    "    confusion_matrix_1d = confusion_matrix(label, pred_l).ravel()\n",
    "    confusion_dict = {N: n for N, n in zip(['tn', 'fp', 'fn', 'tp'], list(\n",
    "        confusion_matrix_1d * 2 / np.sum(confusion_matrix_1d)))}\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(label, pred)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    \n",
    "    evaluation = {\n",
    "        \"accuracy\": accuracy_score(label, pred_l),\n",
    "        \"precision\": precision_score(label, pred_l),\n",
    "        \"f1_score\": f1_score(label, pred_l),\n",
    "        \"mmc\": matthews_corrcoef(label, pred_l),\n",
    "        \"rocAUC\": auc(fpr, tpr),\n",
    "        \"prAUC\": pr_auc,\n",
    "        \"specificity\": confusion_dict['tn'] / (confusion_dict['tn'] + confusion_dict['fp']),\n",
    "        \"sensitivity\": confusion_dict['tp'] / (confusion_dict['tp'] + confusion_dict['fn']),\n",
    "        'pro_cutoff': pro_cutoff\n",
    "    }\n",
    "    return evaluation\n",
    "\n",
    "def plot_roc_curve(target, pred, path_to_: str):\n",
    "    fpr, tpr, thresholds = roc_curve(target, pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(19.2, 10.8))\n",
    "    plt.plot(fpr, tpr, color='red', lw=2,\n",
    "             label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='blue', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic (ROC) curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    plt.savefig(f\"{path_to_}\")\n",
    "    plt.clf()\n",
    "    \n",
    "first_greater_than_found = False\n",
    "\n",
    "def get_model():\n",
    "    input1 = tf.keras.Input(shape=(100,))\n",
    "       \n",
    "    embedding_layer = tf.keras.layers.Embedding(21, 100)(input1)\n",
    "    \n",
    "    dorp1 = tf.keras.layers.Dropout(rate=0.2)(embedding_layer)\n",
    "    lstm1 = tf.keras.layers.LSTM(units=100,input_shape = (100,100),return_sequences=True)(dorp1)\n",
    "    \n",
    "    dorp2 = tf.keras.layers.Dropout(rate=0.2)(lstm1)\n",
    "    lstm2 = tf.keras.layers.LSTM(units=100,input_shape = (100,100),return_sequences=True)(dorp2)\n",
    "    \n",
    "    dorp3 = tf.keras.layers.Dropout(rate=0.2)(lstm2)\n",
    "    lstm3 = tf.keras.layers.LSTM(units=100,input_shape = (100,100),return_sequences=True)(dorp3)\n",
    "    \n",
    "    flatten_layer = tf.keras.layers.Flatten()(lstm3)\n",
    "    output_layer = tf.keras.layers.Dense(1,activation='sigmoid')(flatten_layer)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=input1, outputs=output_layer, name='Rnn')\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                  metrics=[\n",
    "                      tf.keras.metrics.BinaryAccuracy(),\n",
    "                      tf.keras.metrics.AUC(name='auc')\n",
    "                  ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "class MyOptimitzer:\n",
    "    def __init__(self,full_X,full_y) -> None:\n",
    "\n",
    "        self.train_best_predicted_pair = None\n",
    "        self.train_best_5C_predicted_pair = None\n",
    "        self.best_predicted_pair = None\n",
    "        self.best_5C_predicted_pair = None\n",
    "        self.end_of_train_time = None\n",
    "        pass\n",
    "        \n",
    "        for Kfold_id, (train_id, test_id) in enumerate(\n",
    "            StratifiedKFold(\n",
    "                n_splits=5,\n",
    "                shuffle=True,\n",
    "                random_state=42\n",
    "            ).split(full_X, full_y)\n",
    "        ):\n",
    "            y_to_train = full_y[train_id].copy()\n",
    "            fiveC_model = get_model()\n",
    "            fiveC_model.fit(\n",
    "                full_X[train_id],\n",
    "                y_to_train,\n",
    "                epochs=100,\n",
    "                batch_size=15,\n",
    "                callbacks=[\n",
    "                tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='val_auc', min_delta=0, patience=3, verbose=0,\n",
    "                mode='auto', baseline=None, restore_best_weights=True\n",
    "                ),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            # 预测并记录\n",
    "            self.best_5C_predicted_pair.append([\n",
    "                np.nan_to_num(fiveC_model.predict_proba(\n",
    "                    X=full_X[test_id]\n",
    "                ), nan=0.0),\n",
    "                full_y[test_id]\n",
    "            ])\n",
    "            self.train_best_5C_predicted_pair.append([\n",
    "                np.nan_to_num(fiveC_model.predict_proba(\n",
    "                    X=full_X[train_id]\n",
    "                ), nan=0.0),\n",
    "                y_to_train\n",
    "            ])\n",
    "\n",
    "        return self\n",
    "    def get_summary(self, path_to_dir: str = None):\n",
    "        os.makedirs(path_to_dir, exist_ok=True)\n",
    "        model_path = \"-\"\n",
    "        \n",
    "\n",
    "        model_path = f\"{path_to_dir}/{self.classifier_name}.pkl\"\n",
    "        if path_to_dir is not None:\n",
    "            with open(model_path, \"bw+\") as f:\n",
    "                pickle.dump(\n",
    "                    self.grid_search, f\n",
    "                )\n",
    "            \n",
    "        training_testing_performance = get_evaluation(\n",
    "            label=self.best_predicted_pair[1],\n",
    "            pred=self.best_predicted_pair[0][:, 1],\n",
    "        )\n",
    "\n",
    "        # 计算5C中的平均表现\n",
    "        FiveFold_result = {}\n",
    "        for keys in training_testing_performance.keys():\n",
    "            value_list = []\n",
    "            for item in self.best_5C_predicted_pair:\n",
    "\n",
    "                item_performance = get_evaluation(\n",
    "                    label=item[1],\n",
    "                    pred=item[0][:, 1],\n",
    "                )\n",
    "                value_list.append(item_performance[keys])\n",
    "\n",
    "            if keys == \"pro_cutoff\":\n",
    "                FiveFold_result[keys] = value_list\n",
    "            else:\n",
    "                FiveFold_result[keys] = sum(value_list) / len(value_list)\n",
    "\n",
    "\n",
    "        return pd.Series({\n",
    "                        \"Classifier_Name\": self.classifier_name,\n",
    "                        \"Optimitied_Param\": dict(self.grid_search.best_params_),\n",
    "                        \"Model_Path\": model_path\n",
    "                    } | FiveFold_result\n",
    "                        )\n",
    "    \n",
    "def load_data(path):\n",
    "    seq = []\n",
    "    with open(path) as pos:\n",
    "        sequence = \"\"\n",
    "        for line in pos:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\">\"):\n",
    "                if sequence and len(sequence) >= 100:  # 检查上一个序列是否符合条件\n",
    "                    seq.append(sequence[:100])  # 存储前 100 个字符的部分\n",
    "                sequence = \"\"  # 重置序列\n",
    "            else:\n",
    "                sequence += line\n",
    "        if sequence and len(sequence) >= 100:  # 检查最后一条序列是否符合条件\n",
    "            seq.append(sequence[:100])\n",
    "    return seq\n",
    "a = 0\n",
    "rate_list = ['1_2','1_10','1_100']\n",
    "for rate in rate_list:\n",
    "    while a<5:\n",
    "        pos_sequence = pd.Series(load_data('data/pos/T5_training_70.fasta'))\n",
    "        neg_sequence = pd.Series(load_data(f'data/T5/70/{a}/all_nT5_70_{rate}.fasta'))\n",
    "        pos_label = pd.Series(np.ones((len(pos_sequence))))\n",
    "        neg_label = pd.Series(np.zeros((len(neg_sequence))))\n",
    "        full_y = pd.concat([pos_label,neg_label])\n",
    "        full_X = pd.concat([pos_sequence,neg_sequence])\n",
    "        \n",
    "        \n",
    "        full_y = np.vstack(full_y.values)\n",
    "        full_X = np.array(full_X)\n",
    "        full_X = [list(string[:100]) for string in full_X]\n",
    "        tokenizer = Tokenizer()\n",
    "        tokenizer.fit_on_texts(full_X)\n",
    "        full_X = tokenizer.texts_to_sequences(full_X)\n",
    "        full_X = np.array(full_X)\n",
    "\n",
    "        model_path_to_save = f'/mnt/md0/Public/T5/model/'\n",
    "        os.makedirs(model_path_to_save, exist_ok=True)\n",
    "\n",
    "        result_list = []\n",
    "        fivecross_result = pd.concat([MyOptimitzer().get_summary(path_to_dir=f\"{model_path_to_save}/\")], axis=1)\n",
    "\n",
    "        fivecross_result_splited = fivecross_result.loc[:, [\n",
    "            \"accuracy\", \"precision\", \"f1_score\", \"mmc\", \"rocAUC\", \"specificity\", \"sensitivity\", \"pro_cutoff\",\"prAUC\"]]\n",
    "        fivecross_result_splited.to_csv(\n",
    "            f\"{model_path_to_save}/5Fold.csv\"\n",
    "        )\n",
    "\n",
    "        series = fivecross_result_splited.sum(axis=0)\n",
    "        result_list.append(series)\n",
    "\n",
    "        pd.concat(\n",
    "        result_list, axis=1,\n",
    "        ).T.to_csv(\n",
    "        f\"{model_path_to_save}/5fold_results.csv\",\n",
    "        index=True\n",
    "        )\n",
    "        a+=1\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wujiam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
